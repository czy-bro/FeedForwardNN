# README

## 实验概述
本实验使用 PyTorch 实现前馈神经网络（Feedforward Neural Network, FNN），用于拟合目标函数：
\[ y = \log_2(x) + \cos(\pi x / 2) \]
并研究数据量、网络深度、学习率、网络宽度和激活函数等超参数对模型性能的影响。

## 实验环境
- **编程语言**: Python 3.x
- **深度学习框架**: PyTorch
- **其他依赖库**: numpy、matplotlib、scikit-learn
- **硬件要求**: 仅使用 CPU 也可完成实验，但推荐使用 GPU 以提高训练速度

## 实验步骤

### 1. 安装必要的库
```bash
pip install torch torchvision numpy matplotlib scikit-learn
```

### 2. 数据生成
- 在区间 \([1,16]\) 内均匀采样得到 \(N\) 个样本，其中 \(N = 200, 2000, 10000\) 三种情况。
- 按照 **训练集：验证集：测试集 = 8:1:1** 的比例划分数据集。
- 目标函数计算对应的 \( y \) 值。

### 3. 模型搭建
- 使用 PyTorch 封装的 `torch.nn.Linear()`、`torch.nn.ReLU()` 等组件构建前馈神经网络。
- 网络结构由超参数决定，包括隐藏层大小（网络宽度）、层数（深度）和激活函数。

### 4. 训练模型
- 采用均方误差 (MSE) 作为损失函数。
- 采用 Adam 优化器进行参数更新。
- 在训练过程中进行 loss 监测，每 100 个 epoch 输出一次损失值。

### 5. 调参分析
- 通过修改网络深度、学习率、网络宽度和激活函数等超参数，观察其对模型性能的影响。
- 以 MSE 作为评价指标，在验证集上测试不同超参数组合的表现。
- 使用 Matplotlib 绘制验证集的原始样本点与预测点，进行可视化分析。

### 6. 模型测试
- 选择在验证集上表现最好的超参数组合，重新训练模型。
- 在测试集上进行 **唯一一次** 测试，记录最终 MSE 结果。

## 结果可视化
- 训练集、验证集、测试集的数据分布图。
- 训练过程中 loss 下降曲线。
- 训练完成后，验证集的真实值与模型预测值的对比可视化。
- 不同超参数对模型性能的影响分析。


